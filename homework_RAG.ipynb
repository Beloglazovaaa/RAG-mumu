{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **ДЗ NN3 - Создание RAG-системы на основе книги или кода с помощью LangChain**",
   "id": "da393730c234bf4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Цель:\n",
    "- Реализовать полностью локальный RAG-пайплайн.\n",
    "- Генерация ответов и эмбеддинги выполняются через Ollama.\n",
    "- Источник знаний — повесть И. С. Тургенева «Му-му» (в формате TXT или PDF)."
   ],
   "id": "813c24f31048e201"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-03T16:35:47.537376Z",
     "start_time": "2025-09-03T16:35:47.534382Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import os\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from textwrap import shorten"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:36:13.336885Z",
     "start_time": "2025-09-03T16:36:12.747161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ],
   "id": "c7fb8b4b3066262f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Конфигурация",
   "id": "ce6b49ea4b910662"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:38:54.857089Z",
     "start_time": "2025-09-03T16:38:54.852824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    TXT_PATH: str = \"data/mumu.txt\"\n",
    "    PDF_PATH: str = \"data/mumu.pdf\"\n",
    "    FALLBACK_PATH: str = \"data/mumu_excerpt.txt\"\n",
    "\n",
    "    # Backends\n",
    "    LLM_BACKEND: str = \"ollama\"\n",
    "    EMBED_BACKEND: str = \"ollama\"\n",
    "\n",
    "    # Модели Ollama\n",
    "    OLLAMA_MODEL: str = \"qwen3:8b\"\n",
    "    OLLAMA_EMBED_MODEL: str = \"nomic-embed-text\"\n",
    "\n",
    "    # Параметры чанков\n",
    "    CHUNK_SIZE: int = 700\n",
    "    CHUNK_OVERLAP: int = 120\n",
    "\n",
    "    # Настройки ретривера\n",
    "    TOP_K: int = 4\n",
    "\n",
    "\n",
    "CFG = Config()"
   ],
   "id": "98e1c3c0f699f04a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fallback-отрывок (чтобы запускался без книги)",
   "id": "23ade820875700a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:38:57.647435Z",
     "start_time": "2025-09-03T16:38:57.644249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ensure_fallback(cfg: Config):\n",
    "    Path(\"data\").mkdir(exist_ok=True)\n",
    "    if not os.path.exists(cfg.FALLBACK_PATH):\n",
    "        excerpt = (\n",
    "            \"Иван Сергеевич Тургенев — «Му-му» (отрывок)\\n\\n\"\n",
    "            \"Герасим — глухонемой дворник при барыне в Москве. Он подобрал щенка и назвал её Му-му.\\n\"\n",
    "            \"Он привязался к собаке, но барыне не понравился лай. Она велела избавиться от собаки.\\n\"\n",
    "            \"Герасим, мучаясь, исполнил приказ и вернулся в деревню.\\n\"\n",
    "        )\n",
    "        Path(cfg.FALLBACK_PATH).write_text(excerpt, encoding=\"utf-8\")"
   ],
   "id": "4c203c42eb90ebf8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Загрузка документов",
   "id": "2fa804802cf6dd1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:42:44.258698Z",
     "start_time": "2025-09-03T16:42:44.255820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_documents(cfg: Config):\n",
    "    if os.path.exists(cfg.TXT_PATH):\n",
    "        print(f\"TXT: {cfg.TXT_PATH}\")\n",
    "        loader = TextLoader(cfg.TXT_PATH, autodetect_encoding=True)\n",
    "        docs = loader.load()\n",
    "    elif os.path.exists(cfg.PDF_PATH):\n",
    "        print(f\"PDF: {cfg.PDF_PATH}\")\n",
    "        loader = PyPDFLoader(cfg.PDF_PATH)\n",
    "        docs = loader.load()\n",
    "    else:\n",
    "        print(f\"Книга не найдена. Использую отрывок: {cfg.FALLBACK_PATH}\")\n",
    "        loader = TextLoader(cfg.FALLBACK_PATH, autodetect_encoding=True)\n",
    "        docs = loader.load()\n",
    "\n",
    "    print(\"Документов:\", len(docs))\n",
    "    return docs"
   ],
   "id": "1c86013e8977f2b5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Сплит на чанки",
   "id": "ad8035d50311aa0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:43:13.650156Z",
     "start_time": "2025-09-03T16:43:13.647147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_documents(docs, cfg: Config):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=cfg.CHUNK_SIZE,\n",
    "        chunk_overlap=cfg.CHUNK_OVERLAP,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    print(f\"Чанков: {len(chunks)} | size={cfg.CHUNK_SIZE} overlap={cfg.CHUNK_OVERLAP}\")\n",
    "    return chunks"
   ],
   "id": "c44ad8c22b1acdd5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Эмбеддинги + FAISS",
   "id": "581c6134132ac6db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:43:44.595828Z",
     "start_time": "2025-09-03T16:43:44.591981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_embeddings(cfg: Config):\n",
    "    print(f\" Embeddings via Ollama → {cfg.OLLAMA_EMBED_MODEL}\")\n",
    "    return OllamaEmbeddings(model=cfg.OLLAMA_EMBED_MODEL)\n",
    "\n",
    "\n",
    "def build_retriever(chunks, embeddings, cfg: Config):\n",
    "    vectordb = FAISS.from_documents(chunks, embeddings)\n",
    "    retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": cfg.TOP_K})\n",
    "    print(f\"FAISS готов. TOP_K={cfg.TOP_K}\")\n",
    "    return retriever"
   ],
   "id": "6b18fb794af8d088",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LLM + RetrievalQA c анти-галлюцинационной инструкцией",
   "id": "592159a4ea31862"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:44:26.443197Z",
     "start_time": "2025-09-03T16:44:26.436503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_llm(cfg: Config):\n",
    "    print(f\"LLM via Ollama → {cfg.OLLAMA_MODEL}\")\n",
    "    return OllamaLLM(model=cfg.OLLAMA_MODEL, temperature=0.2)\n",
    "\n",
    "\n",
    "QA_TEMPLATE = \"\"\"Ты — помощник-литературовед. Отвечай кратко и только по приведённым фрагментам. Если прямого ответа в контексте нет — так и скажи. Не показывай рассуждения, не добавляй теги <think>.\n",
    "\n",
    "Вопрос: {question}\n",
    "\n",
    "Контекст:\n",
    "{context}\n",
    "\n",
    "Ответ:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=QA_TEMPLATE, input_variables=[\"question\", \"context\"])\n",
    "\n",
    "\n",
    "def make_qa_chain(llm, retriever):\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    )\n",
    "    return chain"
   ],
   "id": "7bf7449797d6a433",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Очистка ответа",
   "id": "2aae46e5cfb6c5cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:44:44.760944Z",
     "start_time": "2025-09-03T16:44:44.758480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_answer(text: str) -> str:\n",
    "    # убрать блоки <think>…</think>\n",
    "    text = re.sub(r\"<think>.*?</think>\\s*\", \"\", text, flags=re.DOTALL)\n",
    "    # убрать **жирный** из Markdown\n",
    "    text = re.sub(r\"\\*+\", \"\", text)\n",
    "    return text.strip()"
   ],
   "id": "34b0638ef8a89e67",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Вспомогательная ask() с выводом источников",
   "id": "b82caef2871e13a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T16:59:36.119660Z",
     "start_time": "2025-09-03T16:59:36.112003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ask(qa_chain, question: str, max_len: int = 240):\n",
    "    res = qa_chain.invoke({\"query\": question})  # используем invoke вместо __call__\n",
    "    raw = res.get(\"result\", \"<нет ответа>\")\n",
    "    answer = clean_answer(raw)\n",
    "    sources = res.get(\"source_documents\", [])\n",
    "\n",
    "    print(\"\\n Вопрос:\", question)\n",
    "    print(\"\\n Ответ:\", answer)\n",
    "    print(\"\\n Источники:\")\n",
    "    for i, d in enumerate(sources, 1):\n",
    "        meta = d.metadata if isinstance(d.metadata, dict) else {}\n",
    "        loc = []\n",
    "        if \"source\" in meta:\n",
    "            loc.append(str(meta[\"source\"]))\n",
    "        if \"page\" in meta:\n",
    "            loc.append(f\"page {meta['page']}\")\n",
    "        loc_str = \" | \".join(loc) if loc else \"(метаданные отсутствуют)\"\n",
    "        print(f\"[{i}] {loc_str}\\n{shorten(d.page_content.strip(), max_len)}\\n\")\n",
    "\n",
    "    return {\"answer\": answer, \"sources\": sources}"
   ],
   "id": "573e3dda78637548",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### main(): сборка пайплайна и 3 демо-запроса",
   "id": "d9e8fedd13bec52c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T17:05:40.147386Z",
     "start_time": "2025-09-03T17:04:18.056078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    ensure_fallback(CFG)\n",
    "    docs = load_documents(CFG)\n",
    "    chunks = split_documents(docs, CFG)\n",
    "    embeddings = build_embeddings(CFG)\n",
    "    retriever = build_retriever(chunks, embeddings, CFG)\n",
    "    llm = build_llm(CFG)\n",
    "    qa_chain = make_qa_chain(llm, retriever)\n",
    "\n",
    "    # Пример 1 — факт\n",
    "    ask(qa_chain, \"Как зовут немого героя повести (дворника/плотника)?\")\n",
    "\n",
    "    # Пример 2 — синтез\n",
    "    ask(qa_chain, \"Какие социальные темы поднимает Тургенев в «Му-му», и как эпизод с барыней их проявляет?\")\n",
    "\n",
    "    # Пример 3 — негативный кейс\n",
    "    ask(qa_chain, \"Есть ли в тексте прямое свидетельство, что барыня умерла в конце повести?\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "d11c665cbbe31e0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXT: data/mumu.txt\n",
      "Документов: 1\n",
      "Чанков: 110 | size=700 overlap=120\n",
      " Embeddings via Ollama → nomic-embed-text\n",
      "FAISS готов. TOP_K=4\n",
      "🗣️ LLM via Ollama → qwen3:8b\n",
      "\n",
      " Вопрос: Как зовут немого героя повести (дворника/плотника)?\n",
      "\n",
      " Ответ: Герасим\n",
      "\n",
      " Источники:\n",
      "[1] data/mumu.txt\n",
      "ее за полтинник, с тем только, чтоб он по крайней мере неделю продержал ее на привязи, и тотчас вернулся; но, не доезжая до дому, слез с извозчика и, обойдя двор кругом, с заднего переулка, через забор перескочил на двор: в калитку-то [...]\n",
      "\n",
      "[2] data/mumu.txt\n",
      "Весь следующий день Герасим не показывался, так что вместо его за водой должен был съездить кучер Потап, чем кучер Потап очень остался недоволен. Барыня спросила Гаврилу, исполнено ли ее приказание. Гаврило отвечал, что исполнено. На [...]\n",
      "\n",
      "[3] data/mumu.txt\n",
      "Герасим не изменил своего поведения ни в чем; только с реки он приехал без воды: он как-то на дороге разбил бочку; а на ночь в конюшне он так усердно чистил и тер свою лошадь, что та шаталась, как былинка на ветру, и переваливалась с [...]\n",
      "\n",
      "[4] data/mumu.txt\n",
      "кровать из дубовых досок на четырех чурбанах – истинно богатырскую кровать; сто пудов можно было положить на нее – не погнулась бы; под кроватью находился дюжий сундук; в уголку стоял столик такого же крепкого свойства, а возле [...]\n",
      "\n",
      "\n",
      " Вопрос: Какие социальные темы поднимает Тургенев в «Му-му», и как эпизод с барыней их проявляет?\n",
      "\n",
      " Ответ: Тургенев поднимает темы жестокости, несправедливости и неволи крестьян. Эпизод с барыней проявляет её безразличие к страданиям Муму, подчеркивая социальное неравенство и жестокость барства.\n",
      "\n",
      " Источники:\n",
      "[1] data/mumu.txt\n",
      "барыня, мол, требует твою собаку к себе. Герасим немного изумился, однако подозвал Муму, поднял ее с земли и передал Степану. Степан принес ее в гостиную и поставил на паркет. Барыня начала ее ласковым голосом подзывать к себе. Муму, [...]\n",
      "\n",
      "[2] data/mumu.txt\n",
      "– Муму, Муму, подойди же ко мне, подойди к барыне, – говорила госпожа, – подойди, глупенькая… не бойсь… – Подойди, подойди, Муму, к барыне, – твердили приживалки, – подойди. Но Муму тоскливо оглядывалась кругом и не трогалась с места. [...]\n",
      "\n",
      "[3] data/mumu.txt\n",
      "не будет, и чтобы барыня сделала милость, не гневалась и успокоилась. Барыня, вероятно, не так-то бы скоро успокоилась, да лекарь второпях вместо двенадцати капель налил целых сорок; сила лавровишенья и подействовала – через четверть [...]\n",
      "\n",
      "[4] data/mumu.txt\n",
      "Уже смеркалось, как он вернулся. По его истомленному виду, по неверной походке, по запыленной одежде его можно было предполагать, что он успел обежать пол-Москвы. Он остановился против барских окон, окинул взором крыльцо, на котором [...]\n",
      "\n",
      "\n",
      " Вопрос: Есть ли в тексте прямое свидетельство, что барыня умерла в конце повести?\n",
      "\n",
      " Ответ: Нет.\n",
      "\n",
      " Источники:\n",
      "[1] data/mumu.txt\n",
      "не будет, и чтобы барыня сделала милость, не гневалась и успокоилась. Барыня, вероятно, не так-то бы скоро успокоилась, да лекарь второпях вместо двенадцати капель налил целых сорок; сила лавровишенья и подействовала – через четверть [...]\n",
      "\n",
      "[2] data/mumu.txt\n",
      "надеялся на ее милость и собирался уже отправиться к ней с просьбой, не позволит ли она ему жениться на Татьяне. Он только ждал нового кафтана, обещанного ему дворецким, чтобы в приличном виде явиться перед барыней, как вдруг этой [...]\n",
      "\n",
      "[3] data/mumu.txt\n",
      "Герасим не изменил своего поведения ни в чем; только с реки он приехал без воды: он как-то на дороге разбил бочку; а на ночь в конюшне он так усердно чистил и тер свою лошадь, что та шаталась, как былинка на ветру, и переваливалась с [...]\n",
      "\n",
      "[4] data/mumu.txt\n",
      "барыня, мол, требует твою собаку к себе. Герасим немного изумился, однако подозвал Муму, поднял ее с земли и передал Степану. Степан принес ее в гостиную и поставил на паркет. Барыня начала ее ласковым голосом подзывать к себе. Муму, [...]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Пример 1. Поиск факта",
   "id": "3f2c3bab11b6206a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Вопрос**: *Как зовут немого героя повести (дворника/плотника)?*\n",
    "\n",
    "**Ответ системы**: *Герасим*\n",
    "\n",
    "**Анализ**:\n",
    "Этот пример показывает, что система корректно решает задачу поиска конкретного факта. Имя главного героя встречается в тексте многократно, и ретривер безошибочно извлекает нужные чанки. Ответ совпадает с оригинальным текстом и демонстрирует точность работы RAG при прямых запросах. Это подтверждает, что пайплайн правильно загружает данные, делит их на части и достаёт релевантный фрагмент."
   ],
   "id": "627e450c5a595f45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Пример 2. Синтез информации",
   "id": "3a6d3ee6cb0f2403"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Вопрос**: *Какие социальные темы поднимает Тургенев в «Му-му», и как эпизод с барыней их проявляет?*\n",
    "\n",
    "**Ответ системы**: *Тургенев поднимает темы жестокости, несправедливости и неволи крестьян. Эпизод с барыней проявляет её безразличие к страданиям Муму, подчеркивая социальное неравенство и жестокость барства.*\n",
    "\n",
    "**Анализ**:\n",
    "Здесь задача сложнее: нужно было обобщить информацию из нескольких эпизодов. Ответ системы получился содержательным: она выделила основные социальные мотивы («жестокость», «несправедливость», «невольное положение крестьян») и связала их с поведением барыни. Это верная интерпретация, которая соответствует критическому прочтению текста. Таким образом, система показала способность не только извлекать факты, но и синтезировать смысл из разных мест повести."
   ],
   "id": "bc893929cdcf489e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Пример 3. Сложный или «негативный» случай",
   "id": "d64ffb067c30beae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Вопрос**: *Есть ли в тексте прямое свидетельство, что барыня умерла в конце повести?*\n",
    "**Ответ**: *Нет.*\n",
    "\n",
    "**Анализ**:\n",
    "Это провокационный вопрос, так как в некоторых пересказах можно встретить утверждение о смерти барыни. Однако в оригинальном тексте Тургенева её смерть не описана: упоминается только эпизод с недомоганием, после чего повествование сосредотачивается на судьбе Герасима. Система дала корректный ответ — в тексте нет прямого свидетельства смерти. Такой результат демонстрирует важное свойство RAG-подхода: способность не придумывать информацию, а честно фиксировать её отсутствие."
   ],
   "id": "8cfe45ce4e0578fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "465d7cb4e56c81a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
